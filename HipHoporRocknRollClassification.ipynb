{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 0. Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","# Import train_test_split function and Decision tree classifier\n","from sklearn.model_selection import train_test_split\n","# Import the StandardScaler\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold, cross_val_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.pipeline import Pipeline\n","\n"]},{"cell_type":"markdown","metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 1. Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"3"},"tags":["sample_code"]},"outputs":[],"source":["\n","# read in data\n","tracks = pd.read_csv('datasets/fma-rock-vs-hiphop.csv')\n","echonest_metrics = pd.read_json('datasets/echonest-metrics.json', precise_float=True)\n","# merge the relevant on track_id col\n","echo_tracks = echonest_metrics.merge(tracks[['genre_top', 'track_id']], on='track_id')\n","\n","echo_tracks.info()"]},{"cell_type":"markdown","metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 2. EDA\n","To maintain efficiency and clarity in our models, we avoid using data points that are too similar, identifying such redundancies with a correlational matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"10"},"tags":["sample_code"]},"outputs":[],"source":["corr_metrics = echonest_metrics.corr()\n","corr_metrics.style.background_gradient()"]},{"cell_type":"markdown","metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 3. Splitting our data\n","Since we found no strong correlations between our features, we can proceed to split our data into two arrays: one for features and another for labels, which is the genre of the track, and then apply preprocessing steps to optimize our model development."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"17"},"tags":["sample_code"]},"outputs":[],"source":["# features\n","features = echo_tracks.drop([\"genre_top\", \"track_id\"], axis=1).values\n","\n","# labels\n","labels = echo_tracks[\"genre_top\"].values\n","\n","# train test split\n","train_features, test_features, train_labels, test_labels = train_test_split(features, labels, \n","                                                                            random_state=10)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 4. Normalizing the feature data\n","Since we didn't find strong correlations between our features, we can use principal component analysis (PCA) to reduce the number of features by rotating the data to highlight the most variance. However, PCA can be biased by features with wider value ranges, so we'll first standardize our features to have a mean of 0 and a standard deviation of 1, ensuring a fair comparison across all features."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"24"},"tags":["sample_code"]},"outputs":[],"source":["# Scaling features (train and test)\n","scaler = StandardScaler()\n","scaled_train_features = scaler.fit_transform(train_features)\n","scaled_test_features = scaler.transform(test_features)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 5. PCA\n","Having preprocessed our data, we're ready to apply PCA to explore dimensionality reduction. We'll use scree-plots and cumulative explained ratio plots to determine the optimal number of components. Scree-plots, which plot components against the variance they explain, help us identify where the variance explained significantly drops off, known as the 'elbow', which indicates an appropriate cutoff for the number of components to use."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"31"},"tags":["sample_code"]},"outputs":[],"source":["%matplotlib inline\n","# Explained variance (all features)\n","pca = PCA()\n","pca.fit(scaled_train_features)\n","exp_variance = pca.explained_variance_ratio_\n","\n","# plotting explained variance\n","fig, ax = plt.subplots()\n","ax.bar(range(pca.n_components_), exp_variance)\n","ax.set_xlabel('Principal Component #')"]},{"cell_type":"markdown","metadata":{"dc":{"key":"38"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 6. Further visualization of PCA\n","Even though the scree plot doesn’t clearly show where to cut off, we can use the cumulative explained variance plot to help. By aiming to explain about 85% of the variance, we can figure out how many components to keep. This way, we can reduce our data’s complexity effectively while still capturing most of its important information."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"38"},"tags":["sample_code"]},"outputs":[],"source":["# cumulative explained variance\n","cum_exp_variance = np.cumsum(exp_variance)\n","\n","# plotting with line at 0.85\n","fig, ax = plt.subplots()\n","ax.plot(cum_exp_variance)\n","ax.axhline(y=0.85, linestyle='--')"]},{"cell_type":"markdown","metadata":{"dc":{"key":"45"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 7. Projecting on to our features\n","The plot showed that 6 features explain 85% of the variance. Thus, we can use these 6 components in PCA to effectively reduce the dimensionality of our train and test data."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"45"},"tags":["sample_code"]},"outputs":[],"source":["# PCA with 6 components\n","pca = PCA(n_components=6, random_state=10)\n","train_pca = pca.fit_transform(scaled_train_features)\n","test_pca = pca.transform(scaled_test_features)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"52"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 8. Train a decision tree to classify genre\n","Now, with the lower-dimensional PCA projection of our data, we can classify songs into genres using a decision tree. This simple, rule-based classifier uses a tree structure to make binary decisions and categorize data. Decision trees are user-friendly, interpretable, and provide a visual flowchart of how decisions are made based on training data. For example, a decision tree can classify shapes by considering attributes like the number of sides and orientation."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"52"},"tags":["sample_code"]},"outputs":[],"source":["# decision tree\n","tree = DecisionTreeClassifier(random_state=10)\n","tree.fit(train_pca, train_labels)\n","pred_labels_tree = tree.predict(test_pca)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"59"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 9. Compare our decision tree to a logistic regression\n","While our decision tree performs well, it's important not to assume it's the best option without exploring others. Next, we'll try logistic regression, which uses the logistic function to estimate the probability that a data point belongs to a specific class. By comparing the performance metrics of both models, like the false positive and false negative rates, we can determine which algorithm better suits our data."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"59"},"tags":["sample_code"]},"outputs":[],"source":["logreg = LogisticRegression(random_state=10)\n","logreg.fit(train_pca, train_labels)\n","pred_labels_logit = logreg.predict(test_pca)\n","\n","class_rep_tree = classification_report(test_labels, pred_labels_tree)\n","class_rep_log = classification_report(test_labels, pred_labels_logit)\n","\n","print(\"Decision Tree: \\n\", class_rep_tree)\n","print(\"Logistic Regression: \\n\", class_rep_log)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"66"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 10. Balance our data for greater performance\n","Both our models have an average precision of 87%, but there's an issue with misclassification of hip-hop songs as rock. This likely occurs because our dataset contains more rock than hip-hop songs, leading the model to favor the rock classification. To improve the model's fairness, we can adjust the weights of each class in the model's calculations, giving greater importance to the underrepresented hip-hop class to balance the influence of each genre's data points. This adjustment aims to correct the skew caused by uneven sample sizes without altering the inherent value of each class."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"66"},"tags":["sample_code"]},"outputs":[],"source":["# balanced subsetting\n","hop_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Hip-Hop']\n","rock_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Rock']\n","\n","# rock only\n","rock_only = rock_only.sample(hop_only.shape[0], random_state=10)\n","\n","# concat hip_hop and rock dfs\n","rock_hop_bal = pd.concat([rock_only, hop_only])\n","\n","# feature and label creation\n","features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) \n","labels = rock_hop_bal['genre_top']\n","\n","# set train and test set with pca balancing \n","train_features, test_features, train_labels, test_labels = train_test_split(\n","    features, labels, random_state=10)\n","\n","train_pca = pca.fit_transform(scaler.fit_transform(train_features))\n","test_pca = pca.transform(scaler.transform(test_features))"]},{"cell_type":"markdown","metadata":{"dc":{"key":"73"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 11. Does balancing our dataset improve model bias?\n","After balancing our dataset to address the model's bias toward the \"Rock\" classification, we need to test if this change retains overall classification performance while correcting the bias. While we've reduced the size of our dataset in the process, we'll proceed without further dimensionality reduction. Typically, we would apply more rigorous dimensionality reduction strategies in scenarios with very large datasets where computation time is a critical factor."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"73"},"tags":["sample_code"]},"outputs":[],"source":["# trai decision tree on balanced data \n","tree = DecisionTreeClassifier(random_state=10)\n","tree.fit(train_pca, train_labels)\n","pred_labels_tree = tree.predict(test_pca)\n","\n","# training logistic regression on  balanced data\n","logreg = LogisticRegression(random_state=10)\n","logreg.fit(train_pca, train_labels)\n","pred_labels_logit = logreg.predict(test_pca)\n","\n","# comparison\n","print(\"Decision Tree: \\n\", classification_report(test_labels, pred_labels_tree))\n","print(\"Logistic Regression: \\n\", classification_report(test_labels, pred_labels_logit))"]},{"cell_type":"markdown","metadata":{"dc":{"key":"80"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 12. Using cross-validation to evaluate our models\n","Balancing our dataset has successfully mitigated the bias towards the \"Rock\" classification. To rigorously evaluate our models, we'll implement cross-validation (CV), which provides a thorough comparison by testing the models across multiple splits of the data. We'll prepare for CV by setting up pipelines to scale our data, apply PCA, and choose a model, either the `DecisionTree22Classifier` or `LogisticRegression`. Using the K-fold CV method, we'll divide the data into equal subsets, cycling each as a test set while training on the remainder. This approach allows us to compile results from each test to give a comprehensive performance score of our models."]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"80"},"tags":["sample_code"]},"outputs":[],"source":["tree_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=6)), \n","                      (\"tree\", DecisionTreeClassifier(random_state=10))])\n","logreg_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=6)), \n","                        (\"logreg\", LogisticRegression(random_state=10))])\n","\n","# 10-fold cross-validation\n","kf = KFold(10)\n","\n","# training models with KFold cv\n","tree_score = cross_val_score(tree_pipe, features, labels, cv=kf)\n","logit_score = cross_val_score(logreg_pipe, features, labels, cv=kf)\n","\n","# mean of each array o scores\n","print(\"Decision Tree:\", np.mean(tree_score), \"Logistic Regression:\", np.mean(logit_score))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":2}
