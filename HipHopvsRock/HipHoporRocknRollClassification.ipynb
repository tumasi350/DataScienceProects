{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Classifying Music Genres Using Echo Nest Data\n","\n","Want to Answer the question: \"Can we accurately classify music tracks as either Hip-Hop or Rock using machine learning?\"\n","\n","Need to preprocess and balance the dataset, apply PCA for dimensionality reduction, and use decision tree and logistic regression models to classify the tracks, evaluating the model performance using cross-validation."]},{"cell_type":"markdown","metadata":{},"source":["## 0. Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold, cross_val_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.pipeline import Pipeline\n","\n"]},{"cell_type":"markdown","metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 1. Datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"dc":{"key":"3"},"tags":["sample_code"]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 4802 entries, 0 to 4801\n","Data columns (total 10 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   track_id          4802 non-null   int64  \n"," 1   acousticness      4802 non-null   float64\n"," 2   danceability      4802 non-null   float64\n"," 3   energy            4802 non-null   float64\n"," 4   instrumentalness  4802 non-null   float64\n"," 5   liveness          4802 non-null   float64\n"," 6   speechiness       4802 non-null   float64\n"," 7   tempo             4802 non-null   float64\n"," 8   valence           4802 non-null   float64\n"," 9   genre_top         4802 non-null   object \n","dtypes: float64(8), int64(1), object(1)\n","memory usage: 412.7+ KB\n"]}],"source":["# read in data\n","tracks = pd.read_csv('datasets/fma-rock-vs-hiphop.csv')\n","echonest_metrics = pd.read_json('datasets/echonest-metrics.json', precise_float=True)\n","# merge the relevant on track_id col\n","echo_tracks = echonest_metrics.merge(tracks[['genre_top', 'track_id']], on='track_id')\n","\n","echo_tracks.info()"]},{"cell_type":"markdown","metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 2. EDA\n","To maintain efficiency and clarity in our models, we avoid using data points that are too similar, identifying such redundancies with a correlational matrix"]},{"cell_type":"code","execution_count":4,"metadata":{"dc":{"key":"10"},"tags":["sample_code"]},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_67656_row0_col0, #T_67656_row1_col1, #T_67656_row2_col2, #T_67656_row3_col3, #T_67656_row4_col4, #T_67656_row5_col5, #T_67656_row6_col6, #T_67656_row7_col7, #T_67656_row8_col8 {\n","  background-color: #023858;\n","  color: #f1f1f1;\n","}\n","#T_67656_row0_col1 {\n","  background-color: #eae6f1;\n","  color: #000000;\n","}\n","#T_67656_row0_col2 {\n","  background-color: #d2d2e7;\n","  color: #000000;\n","}\n","#T_67656_row0_col3 {\n","  background-color: #9ab8d8;\n","  color: #000000;\n","}\n","#T_67656_row0_col4, #T_67656_row1_col0, #T_67656_row1_col2, #T_67656_row1_col3, #T_67656_row1_col7, #T_67656_row2_col5, #T_67656_row3_col1, #T_67656_row4_col0, #T_67656_row4_col6, #T_67656_row4_col8 {\n","  background-color: #fff7fb;\n","  color: #000000;\n","}\n","#T_67656_row0_col5 {\n","  background-color: #ede7f2;\n","  color: #000000;\n","}\n","#T_67656_row0_col6 {\n","  background-color: #eee8f3;\n","  color: #000000;\n","}\n","#T_67656_row0_col7 {\n","  background-color: #f0eaf4;\n","  color: #000000;\n","}\n","#T_67656_row0_col8 {\n","  background-color: #e8e4f0;\n","  color: #000000;\n","}\n","#T_67656_row1_col4 {\n","  background-color: #bdc8e1;\n","  color: #000000;\n","}\n","#T_67656_row1_col5, #T_67656_row6_col0 {\n","  background-color: #e4e1ef;\n","  color: #000000;\n","}\n","#T_67656_row1_col6, #T_67656_row6_col8 {\n","  background-color: #d9d8ea;\n","  color: #000000;\n","}\n","#T_67656_row1_col8, #T_67656_row6_col4 {\n","  background-color: #f7f0f7;\n","  color: #000000;\n","}\n","#T_67656_row2_col0 {\n","  background-color: #c0c9e2;\n","  color: #000000;\n","}\n","#T_67656_row2_col1 {\n","  background-color: #dddbec;\n","  color: #000000;\n","}\n","#T_67656_row2_col3, #T_67656_row5_col3 {\n","  background-color: #adc1dd;\n","  color: #000000;\n","}\n","#T_67656_row2_col4, #T_67656_row6_col7 {\n","  background-color: #ece7f2;\n","  color: #000000;\n","}\n","#T_67656_row2_col6, #T_67656_row3_col8, #T_67656_row6_col3 {\n","  background-color: #b9c6e0;\n","  color: #000000;\n","}\n","#T_67656_row2_col7 {\n","  background-color: #fdf5fa;\n","  color: #000000;\n","}\n","#T_67656_row2_col8 {\n","  background-color: #73a9cf;\n","  color: #f1f1f1;\n","}\n","#T_67656_row3_col0 {\n","  background-color: #bbc7e0;\n","  color: #000000;\n","}\n","#T_67656_row3_col2 {\n","  background-color: #dcdaeb;\n","  color: #000000;\n","}\n","#T_67656_row3_col4 {\n","  background-color: #d7d6e9;\n","  color: #000000;\n","}\n","#T_67656_row3_col5 {\n","  background-color: #e3e0ee;\n","  color: #000000;\n","}\n","#T_67656_row3_col6 {\n","  background-color: #e2dfee;\n","  color: #000000;\n","}\n","#T_67656_row3_col7, #T_67656_row6_col2 {\n","  background-color: #bfc9e1;\n","  color: #000000;\n","}\n","#T_67656_row4_col1 {\n","  background-color: #9ebad9;\n","  color: #000000;\n","}\n","#T_67656_row4_col2 {\n","  background-color: #f6eff7;\n","  color: #000000;\n","}\n","#T_67656_row4_col3 {\n","  background-color: #b8c6e0;\n","  color: #000000;\n","}\n","#T_67656_row4_col5 {\n","  background-color: #f4eef6;\n","  color: #000000;\n","}\n","#T_67656_row4_col7, #T_67656_row7_col5 {\n","  background-color: #ede8f3;\n","  color: #000000;\n","}\n","#T_67656_row5_col0, #T_67656_row8_col7 {\n","  background-color: #d8d7e9;\n","  color: #000000;\n","}\n","#T_67656_row5_col1, #T_67656_row6_col1 {\n","  background-color: #afc1dd;\n","  color: #000000;\n","}\n","#T_67656_row5_col2 {\n","  background-color: #faf2f8;\n","  color: #000000;\n","}\n","#T_67656_row5_col4 {\n","  background-color: #e1dfed;\n","  color: #000000;\n","}\n","#T_67656_row5_col6, #T_67656_row8_col0 {\n","  background-color: #d3d4e7;\n","  color: #000000;\n","}\n","#T_67656_row5_col7 {\n","  background-color: #f1ebf5;\n","  color: #000000;\n","}\n","#T_67656_row5_col8, #T_67656_row8_col5 {\n","  background-color: #eee9f3;\n","  color: #000000;\n","}\n","#T_67656_row6_col5 {\n","  background-color: #dedcec;\n","  color: #000000;\n","}\n","#T_67656_row7_col0 {\n","  background-color: #d6d6e9;\n","  color: #000000;\n","}\n","#T_67656_row7_col1 {\n","  background-color: #d1d2e6;\n","  color: #000000;\n","}\n","#T_67656_row7_col2 {\n","  background-color: #f3edf5;\n","  color: #000000;\n","}\n","#T_67656_row7_col3 {\n","  background-color: #7dacd1;\n","  color: #f1f1f1;\n","}\n","#T_67656_row7_col4, #T_67656_row7_col8 {\n","  background-color: #d2d3e7;\n","  color: #000000;\n","}\n","#T_67656_row7_col6 {\n","  background-color: #dad9ea;\n","  color: #000000;\n","}\n","#T_67656_row8_col1 {\n","  background-color: #cccfe5;\n","  color: #000000;\n","}\n","#T_67656_row8_col2 {\n","  background-color: #69a5cc;\n","  color: #f1f1f1;\n","}\n","#T_67656_row8_col3 {\n","  background-color: #80aed2;\n","  color: #f1f1f1;\n","}\n","#T_67656_row8_col4 {\n","  background-color: #efe9f3;\n","  color: #000000;\n","}\n","#T_67656_row8_col6 {\n","  background-color: #ced0e6;\n","  color: #000000;\n","}\n","</style>\n","<table id=\"T_67656\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_67656_level0_col0\" class=\"col_heading level0 col0\" >track_id</th>\n","      <th id=\"T_67656_level0_col1\" class=\"col_heading level0 col1\" >acousticness</th>\n","      <th id=\"T_67656_level0_col2\" class=\"col_heading level0 col2\" >danceability</th>\n","      <th id=\"T_67656_level0_col3\" class=\"col_heading level0 col3\" >energy</th>\n","      <th id=\"T_67656_level0_col4\" class=\"col_heading level0 col4\" >instrumentalness</th>\n","      <th id=\"T_67656_level0_col5\" class=\"col_heading level0 col5\" >liveness</th>\n","      <th id=\"T_67656_level0_col6\" class=\"col_heading level0 col6\" >speechiness</th>\n","      <th id=\"T_67656_level0_col7\" class=\"col_heading level0 col7\" >tempo</th>\n","      <th id=\"T_67656_level0_col8\" class=\"col_heading level0 col8\" >valence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_67656_level0_row0\" class=\"row_heading level0 row0\" >track_id</th>\n","      <td id=\"T_67656_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n","      <td id=\"T_67656_row0_col1\" class=\"data row0 col1\" >-0.279829</td>\n","      <td id=\"T_67656_row0_col2\" class=\"data row0 col2\" >0.102056</td>\n","      <td id=\"T_67656_row0_col3\" class=\"data row0 col3\" >0.121991</td>\n","      <td id=\"T_67656_row0_col4\" class=\"data row0 col4\" >-0.283206</td>\n","      <td id=\"T_67656_row0_col5\" class=\"data row0 col5\" >-0.004059</td>\n","      <td id=\"T_67656_row0_col6\" class=\"data row0 col6\" >-0.075077</td>\n","      <td id=\"T_67656_row0_col7\" class=\"data row0 col7\" >0.004313</td>\n","      <td id=\"T_67656_row0_col8\" class=\"data row0 col8\" >0.020201</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row1\" class=\"row_heading level0 row1\" >acousticness</th>\n","      <td id=\"T_67656_row1_col0\" class=\"data row1 col0\" >-0.279829</td>\n","      <td id=\"T_67656_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n","      <td id=\"T_67656_row1_col2\" class=\"data row1 col2\" >-0.189599</td>\n","      <td id=\"T_67656_row1_col3\" class=\"data row1 col3\" >-0.477273</td>\n","      <td id=\"T_67656_row1_col4\" class=\"data row1 col4\" >0.110033</td>\n","      <td id=\"T_67656_row1_col5\" class=\"data row1 col5\" >0.041319</td>\n","      <td id=\"T_67656_row1_col6\" class=\"data row1 col6\" >0.038785</td>\n","      <td id=\"T_67656_row1_col7\" class=\"data row1 col7\" >-0.110701</td>\n","      <td id=\"T_67656_row1_col8\" class=\"data row1 col8\" >-0.085436</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row2\" class=\"row_heading level0 row2\" >danceability</th>\n","      <td id=\"T_67656_row2_col0\" class=\"data row2 col0\" >0.102056</td>\n","      <td id=\"T_67656_row2_col1\" class=\"data row2 col1\" >-0.189599</td>\n","      <td id=\"T_67656_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n","      <td id=\"T_67656_row2_col3\" class=\"data row2 col3\" >0.045345</td>\n","      <td id=\"T_67656_row2_col4\" class=\"data row2 col4\" >-0.118033</td>\n","      <td id=\"T_67656_row2_col5\" class=\"data row2 col5\" >-0.143339</td>\n","      <td id=\"T_67656_row2_col6\" class=\"data row2 col6\" >0.171311</td>\n","      <td id=\"T_67656_row2_col7\" class=\"data row2 col7\" >-0.094352</td>\n","      <td id=\"T_67656_row2_col8\" class=\"data row2 col8\" >0.428515</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row3\" class=\"row_heading level0 row3\" >energy</th>\n","      <td id=\"T_67656_row3_col0\" class=\"data row3 col0\" >0.121991</td>\n","      <td id=\"T_67656_row3_col1\" class=\"data row3 col1\" >-0.477273</td>\n","      <td id=\"T_67656_row3_col2\" class=\"data row3 col2\" >0.045345</td>\n","      <td id=\"T_67656_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n","      <td id=\"T_67656_row3_col4\" class=\"data row3 col4\" >-0.002412</td>\n","      <td id=\"T_67656_row3_col5\" class=\"data row3 col5\" >0.045752</td>\n","      <td id=\"T_67656_row3_col6\" class=\"data row3 col6\" >-0.008645</td>\n","      <td id=\"T_67656_row3_col7\" class=\"data row3 col7\" >0.227324</td>\n","      <td id=\"T_67656_row3_col8\" class=\"data row3 col8\" >0.219384</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row4\" class=\"row_heading level0 row4\" >instrumentalness</th>\n","      <td id=\"T_67656_row4_col0\" class=\"data row4 col0\" >-0.283206</td>\n","      <td id=\"T_67656_row4_col1\" class=\"data row4 col1\" >0.110033</td>\n","      <td id=\"T_67656_row4_col2\" class=\"data row4 col2\" >-0.118033</td>\n","      <td id=\"T_67656_row4_col3\" class=\"data row4 col3\" >-0.002412</td>\n","      <td id=\"T_67656_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n","      <td id=\"T_67656_row4_col5\" class=\"data row4 col5\" >-0.058593</td>\n","      <td id=\"T_67656_row4_col6\" class=\"data row4 col6\" >-0.216689</td>\n","      <td id=\"T_67656_row4_col7\" class=\"data row4 col7\" >0.023003</td>\n","      <td id=\"T_67656_row4_col8\" class=\"data row4 col8\" >-0.145200</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row5\" class=\"row_heading level0 row5\" >liveness</th>\n","      <td id=\"T_67656_row5_col0\" class=\"data row5 col0\" >-0.004059</td>\n","      <td id=\"T_67656_row5_col1\" class=\"data row5 col1\" >0.041319</td>\n","      <td id=\"T_67656_row5_col2\" class=\"data row5 col2\" >-0.143339</td>\n","      <td id=\"T_67656_row5_col3\" class=\"data row5 col3\" >0.045752</td>\n","      <td id=\"T_67656_row5_col4\" class=\"data row5 col4\" >-0.058593</td>\n","      <td id=\"T_67656_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n","      <td id=\"T_67656_row5_col6\" class=\"data row5 col6\" >0.073104</td>\n","      <td id=\"T_67656_row5_col7\" class=\"data row5 col7\" >-0.007566</td>\n","      <td id=\"T_67656_row5_col8\" class=\"data row5 col8\" >-0.017886</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n","      <td id=\"T_67656_row6_col0\" class=\"data row6 col0\" >-0.075077</td>\n","      <td id=\"T_67656_row6_col1\" class=\"data row6 col1\" >0.038785</td>\n","      <td id=\"T_67656_row6_col2\" class=\"data row6 col2\" >0.171311</td>\n","      <td id=\"T_67656_row6_col3\" class=\"data row6 col3\" >-0.008645</td>\n","      <td id=\"T_67656_row6_col4\" class=\"data row6 col4\" >-0.216689</td>\n","      <td id=\"T_67656_row6_col5\" class=\"data row6 col5\" >0.073104</td>\n","      <td id=\"T_67656_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n","      <td id=\"T_67656_row6_col7\" class=\"data row6 col7\" >0.032188</td>\n","      <td id=\"T_67656_row6_col8\" class=\"data row6 col8\" >0.094794</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row7\" class=\"row_heading level0 row7\" >tempo</th>\n","      <td id=\"T_67656_row7_col0\" class=\"data row7 col0\" >0.004313</td>\n","      <td id=\"T_67656_row7_col1\" class=\"data row7 col1\" >-0.110701</td>\n","      <td id=\"T_67656_row7_col2\" class=\"data row7 col2\" >-0.094352</td>\n","      <td id=\"T_67656_row7_col3\" class=\"data row7 col3\" >0.227324</td>\n","      <td id=\"T_67656_row7_col4\" class=\"data row7 col4\" >0.023003</td>\n","      <td id=\"T_67656_row7_col5\" class=\"data row7 col5\" >-0.007566</td>\n","      <td id=\"T_67656_row7_col6\" class=\"data row7 col6\" >0.032188</td>\n","      <td id=\"T_67656_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n","      <td id=\"T_67656_row7_col8\" class=\"data row7 col8\" >0.129911</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_67656_level0_row8\" class=\"row_heading level0 row8\" >valence</th>\n","      <td id=\"T_67656_row8_col0\" class=\"data row8 col0\" >0.020201</td>\n","      <td id=\"T_67656_row8_col1\" class=\"data row8 col1\" >-0.085436</td>\n","      <td id=\"T_67656_row8_col2\" class=\"data row8 col2\" >0.428515</td>\n","      <td id=\"T_67656_row8_col3\" class=\"data row8 col3\" >0.219384</td>\n","      <td id=\"T_67656_row8_col4\" class=\"data row8 col4\" >-0.145200</td>\n","      <td id=\"T_67656_row8_col5\" class=\"data row8 col5\" >-0.017886</td>\n","      <td id=\"T_67656_row8_col6\" class=\"data row8 col6\" >0.094794</td>\n","      <td id=\"T_67656_row8_col7\" class=\"data row8 col7\" >0.129911</td>\n","      <td id=\"T_67656_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x7fa110527370>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["corr_metrics = echonest_metrics.corr()\n","corr_metrics.style.background_gradient()"]},{"cell_type":"markdown","metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 3. Splitting our data\n","Since we found no strong correlations between our features, we can proceed to split our data into two arrays: one for features and another for labels, which is the genre of the track, and then apply preprocessing steps to optimize our model development."]},{"cell_type":"code","execution_count":5,"metadata":{"dc":{"key":"17"},"tags":["sample_code"]},"outputs":[],"source":["# features\n","features = echo_tracks.drop([\"genre_top\", \"track_id\"], axis=1).values\n","\n","# labels\n","labels = echo_tracks[\"genre_top\"].values\n","\n","# train test split\n","train_features, test_features, train_labels, test_labels = train_test_split(features, labels, \n","                                                                            random_state=10)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 4. Normalizing the feature data\n","Since we didn't find strong correlations between our features, we can use principal component analysis (PCA) to reduce the number of features by rotating the data to highlight the most variance. However, PCA can be biased by features with wider value ranges, so we'll first standardize our features to have a mean of 0 and a standard deviation of 1, ensuring a fair comparison across all features."]},{"cell_type":"code","execution_count":6,"metadata":{"dc":{"key":"24"},"tags":["sample_code"]},"outputs":[],"source":["# Scaling features (train and test)\n","scaler = StandardScaler()\n","scaled_train_features = scaler.fit_transform(train_features)\n","scaled_test_features = scaler.transform(test_features)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 5. PCA\n","Having preprocessed our data, we're ready to apply PCA to explore dimensionality reduction. We'll use scree-plots and cumulative explained ratio plots to determine the optimal number of components. Scree-plots, which plot components against the variance they explain, help us identify where the variance explained significantly drops off, known as the 'elbow', which indicates an appropriate cutoff for the number of components to use."]},{"cell_type":"code","execution_count":7,"metadata":{"dc":{"key":"31"},"tags":["sample_code"]},"outputs":[{"data":{"text/plain":["Text(0.5, 0, 'Principal Component #')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["%matplotlib inline\n","# Explained variance (all features)\n","pca = PCA()\n","pca.fit(scaled_train_features)\n","exp_variance = pca.explained_variance_ratio_\n","\n","# plotting explained variance\n","fig, ax = plt.subplots()\n","ax.bar(range(pca.n_components_), exp_variance)\n","ax.set_xlabel('Principal Component #')"]},{"cell_type":"markdown","metadata":{"dc":{"key":"38"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 6. Further visualization of PCA\n","Even though the scree plot doesn’t clearly show where to cut off, we can use the cumulative explained variance plot to help. By aiming to explain about 85% of the variance, we can figure out how many components to keep. This way, we can reduce our data’s complexity effectively while still capturing most of its important information."]},{"cell_type":"code","execution_count":8,"metadata":{"dc":{"key":"38"},"tags":["sample_code"]},"outputs":[{"data":{"text/plain":["<matplotlib.lines.Line2D at 0x7fa0d03edc40>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# cumulative explained variance\n","cum_exp_variance = np.cumsum(exp_variance)\n","\n","# plotting with line at 0.85\n","fig, ax = plt.subplots()\n","ax.plot(cum_exp_variance)\n","ax.axhline(y=0.85, linestyle='--')"]},{"cell_type":"markdown","metadata":{"dc":{"key":"45"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 7. Projecting on to our features\n","The plot showed that 6 features explain 85% of the variance. Thus, we can use these 6 components in PCA to effectively reduce the dimensionality of our train and test data."]},{"cell_type":"code","execution_count":9,"metadata":{"dc":{"key":"45"},"tags":["sample_code"]},"outputs":[],"source":["# PCA with 6 components\n","pca = PCA(n_components=6, random_state=10)\n","train_pca = pca.fit_transform(scaled_train_features)\n","test_pca = pca.transform(scaled_test_features)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"52"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 8. Train a decision tree to classify genre\n","Now, with the lower-dimensional PCA projection of our data, we can classify songs into genres using a decision tree. This simple, rule-based classifier uses a tree structure to make binary decisions and categorize data. Decision trees are user-friendly, interpretable, and provide a visual flowchart of how decisions are made based on training data. For example, a decision tree can classify shapes by considering attributes like the number of sides and orientation."]},{"cell_type":"code","execution_count":10,"metadata":{"dc":{"key":"52"},"tags":["sample_code"]},"outputs":[],"source":["# decision tree\n","tree = DecisionTreeClassifier(random_state=10)\n","tree.fit(train_pca, train_labels)\n","pred_labels_tree = tree.predict(test_pca)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"59"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 9. Compare our decision tree to a logistic regression\n","While our decision tree performs well, it's important not to assume it's the best option without exploring others. Next, we'll try logistic regression, which uses the logistic function to estimate the probability that a data point belongs to a specific class. By comparing the performance metrics of both models, like the false positive and false negative rates, we can determine which algorithm better suits our data."]},{"cell_type":"code","execution_count":11,"metadata":{"dc":{"key":"59"},"tags":["sample_code"]},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree: \n","               precision    recall  f1-score   support\n","\n","     Hip-Hop       0.63      0.62      0.62       235\n","        Rock       0.91      0.91      0.91       966\n","\n","    accuracy                           0.85      1201\n","   macro avg       0.77      0.77      0.77      1201\n","weighted avg       0.85      0.85      0.85      1201\n","\n","Logistic Regression: \n","               precision    recall  f1-score   support\n","\n","     Hip-Hop       0.77      0.54      0.64       235\n","        Rock       0.90      0.96      0.93       966\n","\n","    accuracy                           0.88      1201\n","   macro avg       0.83      0.75      0.78      1201\n","weighted avg       0.87      0.88      0.87      1201\n","\n"]}],"source":["logreg = LogisticRegression(random_state=10)\n","logreg.fit(train_pca, train_labels)\n","pred_labels_logit = logreg.predict(test_pca)\n","\n","class_rep_tree = classification_report(test_labels, pred_labels_tree)\n","class_rep_log = classification_report(test_labels, pred_labels_logit)\n","\n","print(\"Decision Tree: \\n\", class_rep_tree)\n","print(\"Logistic Regression: \\n\", class_rep_log)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"66"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 10. Balance our data for greater performance\n","Both our models have an average precision of 87%, but there's an issue with misclassification of hip-hop songs as rock. This likely occurs because our dataset contains more rock than hip-hop songs, leading the model to favor the rock classification. To improve the model's fairness, we can adjust the weights of each class in the model's calculations, giving greater importance to the underrepresented hip-hop class to balance the influence of each genre's data points. This adjustment aims to correct the skew caused by uneven sample sizes without altering the inherent value of each class."]},{"cell_type":"code","execution_count":12,"metadata":{"dc":{"key":"66"},"tags":["sample_code"]},"outputs":[],"source":["# balanced subsetting\n","hop_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Hip-Hop']\n","rock_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Rock']\n","\n","# rock only\n","rock_only = rock_only.sample(hop_only.shape[0], random_state=10)\n","\n","# concat hip_hop and rock dfs\n","rock_hop_bal = pd.concat([rock_only, hop_only])\n","\n","# feature and label creation\n","features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) \n","labels = rock_hop_bal['genre_top']\n","\n","# set train and test set with pca balancing \n","train_features, test_features, train_labels, test_labels = train_test_split(\n","    features, labels, random_state=10)\n","\n","train_pca = pca.fit_transform(scaler.fit_transform(train_features))\n","test_pca = pca.transform(scaler.transform(test_features))"]},{"cell_type":"markdown","metadata":{"dc":{"key":"73"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 11. Does balancing our dataset improve model bias?\n","After balancing our dataset to address the model's bias toward the \"Rock\" classification, we need to test if this change retains overall classification performance while correcting the bias. While we've reduced the size of our dataset in the process, we'll proceed without further dimensionality reduction. Typically, we would apply more rigorous dimensionality reduction strategies in scenarios with very large datasets where computation time is a critical factor."]},{"cell_type":"code","execution_count":13,"metadata":{"dc":{"key":"73"},"tags":["sample_code"]},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree: \n","               precision    recall  f1-score   support\n","\n","     Hip-Hop       0.82      0.77      0.79       230\n","        Rock       0.78      0.82      0.80       225\n","\n","    accuracy                           0.80       455\n","   macro avg       0.80      0.80      0.80       455\n","weighted avg       0.80      0.80      0.80       455\n","\n","Logistic Regression: \n","               precision    recall  f1-score   support\n","\n","     Hip-Hop       0.84      0.80      0.82       230\n","        Rock       0.81      0.85      0.83       225\n","\n","    accuracy                           0.82       455\n","   macro avg       0.82      0.82      0.82       455\n","weighted avg       0.83      0.82      0.82       455\n","\n"]}],"source":["# trai decision tree on balanced data \n","tree = DecisionTreeClassifier(random_state=10)\n","tree.fit(train_pca, train_labels)\n","pred_labels_tree = tree.predict(test_pca)\n","\n","# training logistic regression on  balanced data\n","logreg = LogisticRegression(random_state=10)\n","logreg.fit(train_pca, train_labels)\n","pred_labels_logit = logreg.predict(test_pca)\n","\n","# comparison\n","print(\"Decision Tree: \\n\", classification_report(test_labels, pred_labels_tree))\n","print(\"Logistic Regression: \\n\", classification_report(test_labels, pred_labels_logit))"]},{"cell_type":"markdown","metadata":{"dc":{"key":"80"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 12. Using cross-validation to evaluate our models\n","Balancing our dataset has successfully mitigated the bias towards the \"Rock\" classification. To rigorously evaluate our models, we'll implement cross-validation (CV), which provides a thorough comparison by testing the models across multiple splits of the data. We'll prepare for CV by setting up pipelines to scale our data, apply PCA, and choose a model, either the `DecisionTree22Classifier` or `LogisticRegression`. Using the K-fold CV method, we'll divide the data into equal subsets, cycling each as a test set while training on the remainder. This approach allows us to compile results from each test to give a comprehensive performance score of our models."]},{"cell_type":"code","execution_count":14,"metadata":{"dc":{"key":"80"},"tags":["sample_code"]},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree: 0.7582417582417582 Logistic Regression: 0.782967032967033\n"]}],"source":["tree_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=6)), \n","                      (\"tree\", DecisionTreeClassifier(random_state=10))])\n","logreg_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=6)), \n","                        (\"logreg\", LogisticRegression(random_state=10))])\n","\n","# 10-fold cross-validation\n","kf = KFold(10)\n","\n","# training models with KFold cv\n","tree_score = cross_val_score(tree_pipe, features, labels, cv=kf)\n","logit_score = cross_val_score(logreg_pipe, features, labels, cv=kf)\n","\n","# mean of each array of scores\n","print(\"Decision Tree:\", np.mean(tree_score), \"Logistic Regression:\", np.mean(logit_score))"]},{"cell_type":"markdown","metadata":{},"source":["The results show that the Logistic Regression model performs better than the Decision Tree model for predicting labels, with accuracies of 78.30% and 75.82% respectively. This means that Logistic Regression is more accurate by about 2.5% in this case. The higher accuracy suggests it's a better choice for this particular dataset. These findings can guide which model to use for more reliable predictions."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":2}
